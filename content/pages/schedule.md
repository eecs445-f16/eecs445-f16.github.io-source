Title:  Schedule

### Lecture 1:  Introduction

### Lecture 2:  Linear Algebra Review
*Monday, September 12, 2016*

* Convex functions: definition and properties
* Constrained vs. unconstrained optimization
* Basic understanding of Lagrange duality

### Lecture 3:  Probability Review & Intro to Optimization
*Wednesday, September 14, 2016*

* Essential concepts in probability
* Mastery of conditional distributions, Bayes rule
* Basic understanding of likelihood

### Lecture 4:  Linear Regression, Part I
*Monday, September 19, 2016*

* Supervised learning regression problem
* Linear regression model
* Objective function and its derivative
* Use matrix algebra to compute the derivative

### Lecture 5:  Linear Regression, Part II
*Wednesday, September 21, 2016*

* Overfitting and why regularization is needed
* MLE formulation of linear regression objective
* MAP formulation of regularized linear regression

### Lecture 6:  Naive Bayes
*Monday, September 26, 2016*

* Naive Bayes model and likelihood
* MLE and MAP
* Conditional independence and implications.
* Generative vs discriminative models

### Lecture 7:  Logistic Regression
*Wednesday, September 28, 2016*

* Undersand the supervised learning classification problem formulation
* Logistic regression model and likelihood
* MLE and MAP
* Newton's method

### Lecture 8:  Support Vector Machines, Part I
*Monday, October 3, 2016*

* Find a linear classifier
* Maximize the margin
* Get an optimization problem with constraints
* Variables have some semantics
* No corresponding probabilistic model

### Lecture 9:  Support Vector Machines, Part II
*Wednesday, October 5, 2016*

* Optimal soft-margin hyperplane objective

### Lecture 10, Bias-Variance Tradeoff
*Monday, October 10, 2016*

* Bias vs Variance
* Visualization of Bias vs Variance
* Model complexity

### Lecture 11, Decision Trees
*Wednesday, October 12, 2016*

* Entropy and mutual information
